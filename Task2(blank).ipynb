{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av_sK6JRQag5"
   },
   "source": [
    "# SIT742: Modern Data Science \n",
    "**(2021 Assessment Task 02 - Data Analytics)**\n",
    "\n",
    "---\n",
    "- Please refer to the CloudDeakin for the detailed assessment requirements.\n",
    "- Please submit to Clouddeakin before the due date.\n",
    "- It is a group assignment, and please form a group and self-enrol into the CloudDeakin groups.\n",
    "- Students with difficulty in meeting the deadline because of illness, etc. must apply for an assignment extension in CloudDeakin no later than *12:00pm on 21/05/2021 (Friday)*.\n",
    "\n",
    "\n",
    "Prepared by **SIT742 Teaching Team**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Enter your group information in the following cell.   \n",
    "</div>\n",
    "\n",
    "**Student Information:** Please fill your group information below\n",
    "\n",
    "- Group ID:\n",
    "- Names:  \n",
    "- Student IDs:  \n",
    "- Emails:  \n",
    "- Lab Session and Tutor (for on campus students): \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Part I - Web Log Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "Hotel TULIP a five-star hotel located at Deakin University, and its CIO Dr Bear Guts has asked the Team-SIT742 team to analyse the weblogs files. Hence, Hotel TULIP would like you *Group-SIT742* (a hypothetical data analytics group with up to 3 data analysers) to analyse web log files and discover user accessing patterns of different web pages. \n",
    "\n",
    "In this part, you are required to use give dataset to finish some required analysis, with the exploreation data analytics skills as well as visuilization skill.\n",
    "\n",
    "\n",
    "You will be required to complete the coding to answer the questions with a neat and clean format, and you must keep outputs for code. Your commenting and adherence to code standards will also be considered when marking. Further information on Python standards, please visit https://www.python.org/dev/peps/pep-0008/ \n",
    "\n",
    "\n",
    "**Note**: You are not restricted to the partial code provided, and you can write your own code to implement the required tasks. But you should provide sufficient comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gamCnd8GKEJ7"
   },
   "source": [
    "## 1.Data ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6Ro64a9KNWs"
   },
   "source": [
    "### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37Nq2m64KP0N"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4RAAnpnKS8d"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Your file might be in a different location, so you need to customize the path\n",
    "all_files = ZipFile('/content/drive/MyDrive/2021SIT742Ass1/HTWebLog_p1.zip', 'r')\n",
    "files = all_files.namelist()\n",
    "\n",
    "data = []\n",
    "# Define the column names\n",
    "ColumnNames=['date','time','s_sitename','s_ip','cs_method','cs_uri_stem','cs_uri_query','s_port','cs_username',\n",
    "             'c_ip','cs(User_Agent)','cs(Referer)','sc_status','sc_substatus','sc_win32_status']\n",
    "\n",
    "#Your code to load data from all log files in the provided zip file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmbO0UE1KrvL"
   },
   "source": [
    "In order to reduce the processing time, we will remove all missing values for data and only select 30% of total data for classification. \n",
    "\n",
    "**Code**: \n",
    "    1. Remove all NAs, for the columns, if the column is with 15% NAs, you need to remove that column. Then, for the rows, if there are any NAs in that row, you need to remove that row (requests)  \n",
    "    2. select 30\\% of the total data in to a new dataframe weblog_df.\n",
    "    \n",
    "    *Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    The number of requests in weblog\\_df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code to remove missing values as required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KzcKdcmKzMR"
   },
   "outputs": [],
   "source": [
    "# only 30% of total data are selected for classification\n",
    "weblog_df = df_ht.sample(frac = 0.3, random_state=1)\n",
    "\n",
    "#Your code to show the number of requests in weblog_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaKs1Ic5Ln8F"
   },
   "source": [
    "### 1.2 Feature Selection\n",
    "\n",
    "**Code**: \n",
    "    You are required to select *'cs_method'*,*'cs_ip'*,*'cs_uri_stem'*,*'cs(Referer)'* as input features  and 'sc_status' as class label into a new dataframe ml_df for following Machine Learning Tasks. \n",
    "\n",
    "*Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    1. Data Description of ml_df,  \n",
    "    2. Print top 5 rows of ml_df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "begZOxggN2A8"
   },
   "outputs": [],
   "source": [
    "# Your code for feature selection\n",
    "\n",
    "\n",
    "\n",
    "#Your code to show the top 5 rows of ml_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1j3dndKNMgDO"
   },
   "source": [
    "## 2.Unsupervised Learning\n",
    " You are required to complete this part only using **sklearn**.\n",
    "\n",
    "\n",
    "**Code**: \n",
    "    1. Perform unsupervised learning on ml_df with K Means, with a varying K from 2 to 10;\n",
    "    2. Plot in the elbow plot. \n",
    "    \n",
    "    *Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    1. Figure 'KMeans' in the elbow plot, with a varying K from 2 to 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0m6R9R5N6Kq"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_df = ml_df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "\n",
    "#Your code for Kmeans\n",
    "\n",
    "\n",
    "#Your code for visualizing K means result as elbow plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU6zSmu0OEHC"
   },
   "source": [
    "## 3.Supervised Learning\n",
    " You are required to complete this part only using **PySpark**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fh8-pmiTQuza"
   },
   "outputs": [],
   "source": [
    "# install Java8\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# download spark 3.1.1\n",
    "!wget -q http://apache.osuosl.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "# unzip it\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "# install findspark \n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\n",
    "import findspark \n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRzcbPF4Pskq"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName('SIT742T2').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RncKyIESOMnJ"
   },
   "source": [
    "### 3.1 Data Preparation \n",
    "\n",
    "In order to reduce the processing time, we will select 10% of le_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DE23Ll_fOS5J"
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"sc-status\", IntegerType(), True),\n",
    "                     StructField(\"cs-method\", IntegerType(), True),\n",
    "                     StructField(\"c-ip\", IntegerType(), True),\n",
    "                     StructField(\"cs-uri-stem\", IntegerType(), True),\n",
    "                     StructField(\"cs(Referer)\", IntegerType(), True)])\n",
    "\n",
    "lr_df = spark.createDataFrame(le_df, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJdQe_8tPvlF"
   },
   "outputs": [],
   "source": [
    "#Only 10% of the data is used in this part.\n",
    "lr_df = le_df.sample(fraction=0.1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut3zjBOyU2FU"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "# transformer\n",
    "vector_assembler = VectorAssembler(inputCols=['cs-method', 'c-ip', 'cs-uri-stem', 'cs(Referer)'],outputCol=\"features\")\n",
    "df_temp = vector_assembler.transform(lr_df )\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBoKE5tYVdXj"
   },
   "outputs": [],
   "source": [
    "df_lr = df_temp.drop('cs-method', 'c-ip', 'cs-uri-stem', 'cs(Referer)')\n",
    "df_lr.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12YtMZE0OTOR"
   },
   "source": [
    "###  3.2 Logistic Regression\n",
    "\n",
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "    1. Perform supervised learning on ml\\_df with Logistic Regression,  <br>\n",
    "    2. Evaluate the classification result using [confusion matrix ](https://en.wikipedia.org/wiki/Confusion_matrix) including TP, TN, FP, FN, <br>\n",
    "    3. Evaluate the classification result using Precision, Recall and F1 score.\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    1. Display the classification result using [confusion matrix ](https://en.wikipedia.org/wiki/Confusion_matrix) including TP, TN, FP, FN, <br>\n",
    "    2. Display the classification result using Precision, Recall and F1 score.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_XZqsSAOr4a"
   },
   "outputs": [],
   "source": [
    "#Create the data sets for training and testing\n",
    "(trainingData, testData) = df_lr.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19Ri7rpuOxk6"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your code contains trainning from train data and predicting based on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66ESM5L3O1cp"
   },
   "outputs": [],
   "source": [
    "# Your code to display TP, TN, FP, FN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BZB16gVO2pq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Your Code to display the classification results as required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt5iA23HO5uC"
   },
   "source": [
    "### 3.3 K-fold Cross-Validation\n",
    "You are required to use K-fold cross validation to find out the best hyper-parameter set, where K = 2.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "Implement 2-fold cross validation for three (any three) classification models, where K = 2.\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    1.  Your code design and running results, <br>\n",
    "\t\t2.  Your findings on hyper-parameters based on this cross-validation  results (Best results).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgJtFjqKPEFD"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# K = 2\n",
    "# Your code for 2-fold cross validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ThOmZbnPyMa"
   },
   "source": [
    "## 4.Association Rule Mining\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "Implement association rule mining with a suitable threshold for support, and confidence \n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "\n",
    "**Report**:\n",
    "    1.  Your code design and running results, <br>\n",
    "\t\t2.  Your findings on on ARMing results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtZ5-w3tQJDl"
   },
   "outputs": [],
   "source": [
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLR-Vp-cQPki"
   },
   "outputs": [],
   "source": [
    "# you can also use PySpark package, if preferred\n",
    "from apyori import apriori\n",
    "\n",
    "# Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX5Kb_DPQ3cE"
   },
   "source": [
    "# Part II - Web Crawling\n",
    "\n",
    "## Overview\n",
    "In 2021, \n",
    "to better introduce and understand the research works on the professors,\n",
    "Deakin university wants to perform the citation prediction on individual professor level.\n",
    "You are required to implement a web crawler to crawl the *citation* information \n",
    "for A/Professor Gang Li from 2003 to 2021 (start at 2003 and end at 2021),\n",
    "and also conduct several prediction coding tasks. \n",
    "You will need to make sure that \n",
    "the web crawling code and prediction code meets the requirements.\n",
    "You are free to use any **Python** package for Web crawling and prediction \n",
    "by finishing below tasks.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REp-ATy8gGyS"
   },
   "source": [
    "## 5.Crawl Gang Li citation information from 2003 to 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99Y04DfvFMGO"
   },
   "source": [
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "    You are required to write the code to generate the csv for Gang Li's citation from 2003 to 2021\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpyNYt7B7_V8"
   },
   "outputs": [],
   "source": [
    "# Your code to crawl and generate the csv, and save it to variable create_df\n",
    "#import pandas as pd\n",
    "#create_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDs8ETNWII8b"
   },
   "source": [
    "## 6.Train Arima to predict the 2018 to 2020 citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtKVVs6wGXwc"
   },
   "source": [
    "### 6.1 Train Arima Model\n",
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "    You will need to use the create_df and then perform the\n",
    "Arima training with parameter of $p=1$, $q=1$ and $d=1$ on data from 2003 to 2017 (15 years)\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5azaduXOGd5_"
   },
   "outputs": [],
   "source": [
    "# your code to use create_df to split the data into train (year 2003 to 2017) and test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iomydVFJGdFQ"
   },
   "source": [
    "### 6.2 Predicting the citation and Calculate the RMSE\n",
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "    you will need to use the trained Arime model to predict the citation on year 2018, 2019 and 2020.\n",
    "You will need to perform the evaluation by comparing the predicted citation from 2018 to 2020 with \n",
    "the true citation from 2018 to 2020 and calculate the RMSE (root mean square error).\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cqMwQw2Gqh1"
   },
   "outputs": [],
   "source": [
    "# your code to predict the citation and save it to variable preds. You may need to output the confidence interval(95%) here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mq1fAKXTIdU4"
   },
   "outputs": [],
   "source": [
    "# Print the error below by comparing the test and preds:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Your code to show the performance RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7k3Savqewxg"
   },
   "source": [
    "### 6.3 Draw the visualization to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JC5xseYSH7ze"
   },
   "source": [
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "   You will also need to use matplotlib to draw the line plot with training data from 2013 to 2017,\n",
    "the testing truth, the prediction and also the confidence interval (95%). \n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcsJIrOXItA5"
   },
   "outputs": [],
   "source": [
    "# You code: Visualize as required, the prediction with its confidence interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qhi7QJhPenf"
   },
   "source": [
    "## 7.Conduct the Grid Search with paramter selection and then predict the 2021 and 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie6-3EY_IdT3"
   },
   "source": [
    "### 7.1 Grid Search\n",
    " <div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "  You will need to run the grid search for parameter $p=[1,2]$, \n",
    "$q=[1,2]$,\n",
    "$d=[1,2]$\n",
    "with training data on year 2003 to 2017 and testing data on 2018 to 2020\n",
    "The result of the search on each paratemer combination (eg: p=1,q=1,d=1)\n",
    "will need to be stored in the \"search-results.csv\",\n",
    "The search-results.csv will have the column of \"RMSE\" and column \"PARAMETER\".\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9l3SYph7Psk3"
   },
   "outputs": [],
   "source": [
    "# your code to run grid search\n",
    "#p = list(range(1,3))\n",
    "#q = list(range(1,3))\n",
    "#d = list(range(1,3))\n",
    "#RMSE = []\n",
    "#PARAMETER = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gax9Nx6zQ7hH"
   },
   "outputs": [],
   "source": [
    "# your code to generate the seach-results.csv and print the top 6 rows\n",
    "#Results = pd.DataFrame({'RMSE':RMSE,'Parameter':PARAMETER})\n",
    "#Results.head(6)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTey6Y9ER0rE"
   },
   "source": [
    "### 7.2 TRAIN With Best Parameter Set with data up to 2020 and Predict the 2021 and 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skoPt98jJTro"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "  You will need to perform the training with Arima on data from 2003 to 2020 with best parameter you have found in last task,\n",
    "and then conduct the prediction for year 2021 and 2022.\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKSwlnWRRzQ3"
   },
   "outputs": [],
   "source": [
    "# your code to perform the Arima train on data 2003 to 2020\n",
    "#train = create_df.citation_all.values[:-1]\n",
    "\n",
    "\n",
    "# Your code to predict for 2021 and 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3TCMUg1JyNj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Code**: \n",
    "  You will also need to use matplotlib to draw the line plot with training data from 2013 to 2020, the prediction and also the confidence interval (95%).\n",
    "    <br>\n",
    "    *Keep the outputs for code in your notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMTaDurDSVjj"
   },
   "outputs": [],
   "source": [
    "# Plot the points and the prediction with its confidence interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III - Self-Reflective Essay\n",
    "\n",
    "## Overview\n",
    "\n",
    "Please check the assessment task specification details.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021SIT742Task2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
